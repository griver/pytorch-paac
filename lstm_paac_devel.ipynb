{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Test LSTMCell\n",
    "========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rand_inputs(shape, precision=1):\n",
    "    inputs = th.randn(*shape)*(10**1)\n",
    "    inputs = inputs.round()/(10**1) \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 inputs: torch.Size([3, 10])\n",
      "h_old:\n",
      "[[ 0.9 -1.8 -0.2 -0.8  1. ]\n",
      " [-0.2 -0.1 -1.7 -0.1 -0.1]\n",
      " [-0.7 -0.3  0.1 -0.5  1.2]]\n",
      "h_new:\n",
      "[[ 0.007  0.06   0.071  0.314  0.225]\n",
      " [ 0.092  0.009  0.028  0.005 -0.171]\n",
      " [-0.01  -0.135  0.164  0.351  0.098]]\n",
      "1 inputs: torch.Size([3, 10])\n",
      "h_old:\n",
      "[[ 0.007  0.06   0.071  0.314  0.225]\n",
      " [ 0.092  0.009  0.028  0.005 -0.171]\n",
      " [-0.01  -0.135  0.164  0.351  0.098]]\n",
      "h_new:\n",
      "[[ 0.003  0.346 -0.073  0.19   0.087]\n",
      " [-0.1    0.204  0.063  0.095 -0.181]\n",
      " [-0.189 -0.103  0.182  0.152 -0.101]]\n",
      "2 inputs: torch.Size([3, 10])\n",
      "h_old:\n",
      "[[ 0.003  0.346 -0.073  0.19   0.087]\n",
      " [-0.1    0.204  0.063  0.095 -0.181]\n",
      " [-0.189 -0.103  0.182  0.152 -0.101]]\n",
      "h_new:\n",
      "[[-0.153  0.413  0.224  0.188 -0.021]\n",
      " [-0.242  0.292  0.237  0.214 -0.309]\n",
      " [-0.161  0.192 -0.038  0.098  0.054]]\n",
      "3 inputs: torch.Size([3, 10])\n",
      "h_old:\n",
      "[[-0.153  0.413  0.224  0.188 -0.021]\n",
      " [-0.242  0.292  0.237  0.214 -0.309]\n",
      " [-0.161  0.192 -0.038  0.098  0.054]]\n",
      "h_new:\n",
      "[[-0.116  0.293 -0.041  0.243 -0.061]\n",
      " [-0.183  0.353  0.285  0.273 -0.195]\n",
      " [-0.201  0.178  0.227 -0.195 -0.373]]\n",
      "4 inputs: torch.Size([3, 10])\n",
      "h_old:\n",
      "[[-0.116  0.293 -0.041  0.243 -0.061]\n",
      " [-0.183  0.353  0.285  0.273 -0.195]\n",
      " [-0.201  0.178  0.227 -0.195 -0.373]]\n",
      "h_new:\n",
      "[[ 0.144  0.274  0.026  0.205 -0.159]\n",
      " [ 0.05   0.001 -0.02   0.18  -0.145]\n",
      " [-0.147  0.247  0.214  0.153 -0.161]]\n",
      "5 inputs: torch.Size([3, 10])\n",
      "h_old:\n",
      "[[ 0.144  0.274  0.026  0.205 -0.159]\n",
      " [ 0.05   0.001 -0.02   0.18  -0.145]\n",
      " [-0.147  0.247  0.214  0.153 -0.161]]\n",
      "h_new:\n",
      "[[ 0.039  0.553 -0.008  0.286 -0.024]\n",
      " [ 0.202  0.027  0.022  0.111 -0.171]\n",
      " [-0.262  0.404  0.006  0.291 -0.1  ]]\n"
     ]
    }
   ],
   "source": [
    "T = 6\n",
    "batch_size = 3\n",
    "input_dim = 10\n",
    "output_dim = 5\n",
    "%precision 3\n",
    "rnn = nn.LSTMCell(input_dim, output_dim, bias=True)\n",
    "inputs = Variable(rand_inputs([T, batch_size, input_dim]))\n",
    "h = Variable(rand_inputs([batch_size, output_dim], precision=2))\n",
    "c = Variable(rand_inputs([batch_size, output_dim], precision=2))\n",
    "output = []\n",
    "for t in range(T):\n",
    "    print(t, 'inputs:', inputs[t].size())\n",
    "    h_new, c_new = rnn(inputs[t], (h, c))\n",
    "    print('h_old:', h.data.numpy(), sep='\\n')\n",
    "    print('h_new:', h_new.data.numpy(), sep='\\n')\n",
    "    h, c = h_new, c_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM ForgetGates initialization:\n",
    "================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forgetgate coords: 5 10\n",
      "bias_ih: [ 0.306  0.313  0.295  0.409 -0.055 -0.371 -0.002 -0.3    0.189 -0.429\n",
      " -0.252  0.005 -0.355 -0.06   0.18  -0.045 -0.328 -0.078  0.005  0.049]\n",
      "bias_ih: [ 0.  0.  0.  0.  0.  5.  5.  5.  5.  5.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "all gates_shape: torch.Size([1, 20])\n",
      "ingate:\n",
      "mean: [ 0.514]\n",
      "[[ 0.454  0.722  0.557  0.408  0.429]]\n",
      "forgetgate:\n",
      "mean: [ 0.993]\n",
      "[[ 0.996  0.998  0.996  0.979  0.996]]\n",
      "cellgate:\n",
      "mean: [ 0.149]\n",
      "[[-0.89   0.258 -0.142  0.923  0.596]]\n",
      "outgate:\n",
      "mean: [ 0.506]\n",
      "[[ 0.65   0.38   0.588  0.572  0.341]]\n"
     ]
    }
   ],
   "source": [
    "def test_lstm(cell, batch_size):\n",
    "    bias_size = cell.bias_ih.size()[0]\n",
    "    forget_start, forget_end = bias_size//4, bias_size//2\n",
    "    print('forgetgate coords:', forget_start, forget_end)\n",
    "    print('bias_ih:', cell.bias_ih.data.numpy())\n",
    "    cell.bias_ih.data.fill_(0.)\n",
    "    cell.bias_ih.data[forget_start:forget_end].fill_(5.)\n",
    "    \n",
    "    print('bias_ih:', cell.bias_ih.data.numpy())\n",
    "    inputs = th.ones(batch_size, cell.input_size)\n",
    "    gates = F.linear(Variable(inputs), cell.weight_ih, cell.bias_ih)\n",
    "    \n",
    "    print('all gates_shape:', gates.size())\n",
    "    gates = gates.chunk(4, 1)\n",
    "    gate_names = ['ingate', 'forgetgate','cellgate', 'outgate']\n",
    "    gate_funcs = [F.sigmoid, F.sigmoid, F.tanh, F.sigmoid]\n",
    "        \n",
    "    for name,gate, nl in zip(gate_names, gates, gate_funcs):\n",
    "        out = nl(gate)\n",
    "        print('{0}:'.format(name), 'mean: {0}'.format(out.mean().data.numpy()), out.data.numpy(), sep='\\n')\n",
    "\n",
    "rnn = nn.LSTMCell(input_dim, output_dim, bias=True)\n",
    "test_lstm(rnn, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_bias size: torch.Size([1024])\n",
      "ingate       size:256 biases mins: (0.0, 0.0) biases maxs: (0.0, 0.0)\n",
      "forgetgate   size:256 biases mins: (0.5, 0.5) biases maxs: (0.5, 0.5)\n",
      "cellgate     size:256 biases mins: (0.0, 0.0) biases maxs: (0.0, 0.0)\n",
      "outgate      size:256 biases mins: (0.0, 0.0) biases maxs: (0.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "def check_lstm_init():\n",
    "    from network import LSTMNetwork, FFNetwork\n",
    "    net = LSTMNetwork(4, th.cuda.FloatTensor)\n",
    "    bias_ih, bias_hh = net.lstm.bias_ih, net.lstm.bias_hh\n",
    "    print('lstm_bias size:', bias_ih.size())\n",
    "    hidden_size = net.lstm.hidden_size\n",
    "    gates_names = ['ingate', 'forgetgate', 'cellgate', 'outgate']\n",
    "    for i, gate_name in enumerate(gates_names):\n",
    "        gate_ih = bias_ih.data[hidden_size*i:hidden_size*(i+1)]\n",
    "        gate_hh = bias_hh.data[hidden_size*i:hidden_size*(i+1)]\n",
    "        print('{0:<12} size:{1}'.format(gate_name, gate_ih.size()[0]), end=' ')\n",
    "        print('biases mins:', (gate_ih.min(), gate_hh.min()), end=' ')\n",
    "        print('biases maxs:', (gate_ih.max(), gate_hh.max()))\n",
    "\n",
    "check_lstm_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init LSTMnet:\n",
      "CONV2D_INIT: Conv2d(3, 16, kernel_size=(8, 8), stride=(4, 4))\n",
      "CONV2D_INIT: Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))\n",
      "LSTM_INIT: LSTMCell(2592, 256)\n",
      "LINEAR_INIT: Linear (256 -> 4)\n",
      "LINEAR_INIT: Linear (256 -> 1)\n",
      "\n",
      "\n",
      "init FFnet:\n",
      "CONV2D_INIT: Conv2d(4, 16, kernel_size=(8, 8), stride=(4, 4))\n",
      "CONV2D_INIT: Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))\n",
      "LINEAR_INIT: Linear (2592 -> 256)\n",
      "LINEAR_INIT: Linear (256 -> 4)\n",
      "LINEAR_INIT: Linear (256 -> 1)\n"
     ]
    }
   ],
   "source": [
    "def check_net_init():\n",
    "    print('init LSTMnet:')\n",
    "    from network import LSTMNetwork, FFNetwork\n",
    "    net = LSTMNetwork(4, th.cuda.FloatTensor)\n",
    "    print('\\n\\ninit FFnet:')\n",
    "    net = FFNetwork(4, th.cuda.FloatTensor)\n",
    "    \n",
    "check_net_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Simple example to check gradients correctness after clone() and inplace operations:\n",
    "================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grads for the identity function:\n",
      "W.grads:\n",
      "Variable containing:\n",
      "1.00000e-02 *\n",
      " -8.3333 -8.3333 -8.3333\n",
      " -8.3333 -8.3333 -8.3333\n",
      " -8.3333 -8.3333 -8.3333\n",
      " -8.3333 -8.3333 -8.3333\n",
      "[torch.FloatTensor of size 4x3]\n",
      "\n",
      "W_prime.grads:\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "grads for the complex function:\n",
      "W.grads:\n",
      "Variable containing:\n",
      "1.00000e-02 *\n",
      " -8.3333 -8.3333 -8.3333\n",
      "  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000\n",
      " -8.3333 -8.3333 -8.3333\n",
      "[torch.FloatTensor of size 4x3]\n",
      "\n",
      "W_prime.grads:\n",
      "Variable containing:\n",
      "1.00000e-02 *\n",
      "  0.0000  0.0000  0.0000\n",
      " -8.3333 -8.3333 -8.3333\n",
      " -8.3333 -8.3333 -8.3333\n",
      "  0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 4x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def simple_example(W_prime_grads=False):\n",
    "    def create_W_and_W_prime():\n",
    "        W = Variable(th.zeros(4,3), requires_grad=True)\n",
    "        W_prime = Variable(th.zeros(4,3), requires_grad=W_prime_grads)\n",
    "        return W, W_prime\n",
    "    \n",
    "    def id_fun(a, b):\n",
    "        return a\n",
    "    \n",
    "    def complex_fun(a, b):\n",
    "        output = a.clone()\n",
    "        output[change_rows,:] = b[change_rows,:]\n",
    "        return output\n",
    "    \n",
    "    def print_grads(title, W, W_prime):\n",
    "        print(title)\n",
    "        print('W.grads:', W.grad, sep='\\n')\n",
    "        print('W_prime.grads:', W_prime.grad, sep='\\n')\n",
    "\n",
    "    T = Variable(th.ones(4,3)) # Target\n",
    "    l1 = nn.L1Loss()\n",
    "    change_rows = th.Tensor([0,1,1,0]).nonzero().view(-1)\n",
    "    \n",
    "    W, W_prime = create_W_and_W_prime()\n",
    "    loss = l1(id_fun(W, W_prime), T)\n",
    "    loss.backward()\n",
    "    print_grads('grads for the identity function:', W, W_prime)\n",
    "    print('\\n\\n')\n",
    "    W, W_prime = create_W_and_W_prime()\n",
    "    loss = l1(complex_fun(W, W_prime), T)\n",
    "    loss.backward()\n",
    "    print_grads('grads for the complex function:', W, W_prime)\n",
    "    \n",
    "    \n",
    "simple_example(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
